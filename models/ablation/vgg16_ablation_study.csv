variant,description,val_accuracy,train_accuracy,val_loss,train_loss,parameters,model_size_mb,training_time_s,inference_time_ms
vgg16,Base model,76.62337662337663,75.28571428571429,0.5181101769595952,0.6070918594087873,134289223,512.2822093963623,58.33035349845886,10.739109732887963
vgg16_dropout_0.3,Dropout rate changed to 0.3,74.02597402597402,75.28571428571429,0.5342467576265335,0.5864519344057355,134289223,512.284574508667,57.13658905029297,10.011035126525087
vgg16_dropout_0.7,Dropout rate changed to 0.7,68.83116883116882,71.28571428571429,0.7539755253048687,0.7723737706456866,134289223,512.284574508667,56.147247552871704,9.427383348539278
vgg16_leaky_relu,ReLU activation changed to LeakyReLU,14.285714285714286,15.857142857142858,209385.19937094155,290786.225625,134289223,512.2845401763916,55.29739737510681,9.015358887709581
vgg16_instance_norm,Batch normalization changed to instance normalization,75.32467532467533,73.42857142857143,0.4772243267529971,0.5936248963219779,134289223,512.2846431732178,54.712271213531494,8.522374289376396
vgg16_group_norm,Batch normalization changed to group normalization (one group per channel),74.02597402597402,70.85714285714286,0.6671548795390438,0.7898970999036516,134289223,512.2845401763916,54.203112840652466,8.086876435713336
vgg16_no_dropout,Layer removal not applicable,80.51948051948052,76.28571428571429,0.4539029857554993,0.6076514428002494,134289223,512.2845401763916,53.66042709350586,7.787726142189719
